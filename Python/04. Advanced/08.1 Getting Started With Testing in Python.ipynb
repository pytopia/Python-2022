{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82f5cfd2",
   "metadata": {},
   "source": [
    "<img src=\"../../images/banners/python-advanced.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac75264f",
   "metadata": {},
   "source": [
    "# <img src=\"../../images/logos/python.png\" width=\"23\"/> Getting Started With Testing in Python \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8116099b",
   "metadata": {},
   "source": [
    "## <img src=\"../../images/logos/toc.png\" width=\"20\"/> Table of Contents \n",
    "* [Testing Your Code](#testing_your_code)\n",
    "    * [Automated vs. Manual Testing](#automated_vs._manual_testing)\n",
    "    * [Unit Tests vs. Integration Tests](#unit_tests_vs._integration_tests)\n",
    "    * [Choosing a Test Runner](#choosing_a_test_runner)\n",
    "        * [`unittest`](#`unittest`)\n",
    "        * [`nose`](#`nose`)\n",
    "        * [`pytest`](#`pytest`)\n",
    "* [Writing Your First Test](#writing_your_first_test)\n",
    "    * [Where to Write the Test](#where_to_write_the_test)\n",
    "    * [How to Structure a Simple Test](#how_to_structure_a_simple_test)\n",
    "    * [How to Write Assertions](#how_to_write_assertions)\n",
    "    * [Side Effects](#side_effects)\n",
    "* [Executing Your First Test](#executing_your_first_test)\n",
    "    * [Executing Test Runners](#executing_test_runners)\n",
    "    * [Understanding Test Output](#understanding_test_output)\n",
    "    * [Running Your Tests From PyCharm](#running_your_tests_from_pycharm)\n",
    "    * [Running Your Tests From Visual Studio Code](#running_your_tests_from_visual_studio_code)\n",
    "* [Testing for Web Frameworks Like Django and Flask](#testing_for_web_frameworks_like_django_and_flask)\n",
    "    * [Why They’re Different From Other Applications](#why_they’re_different_from_other_applications)\n",
    "    * [How to Use the Django Test Runner](#how_to_use_the_django_test_runner)\n",
    "    * [How to Use `unittest` and Flask](#how_to_use_`unittest`_and_flask)\n",
    "* [More Advanced Testing Scenarios](#more_advanced_testing_scenarios)\n",
    "    * [Handling Expected Failures](#handling_expected_failures)\n",
    "    * [Isolating Behaviors in Your Application](#isolating_behaviors_in_your_application)\n",
    "    * [Writing Integration Tests](#writing_integration_tests)\n",
    "    * [Testing Data-Driven Applications](#testing_data-driven_applications)\n",
    "* [Testing in Multiple Environments](#testing_in_multiple_environments)\n",
    "    * [Installing Tox](#installing_tox)\n",
    "    * [Configuring Tox for Your Dependencies](#configuring_tox_for_your_dependencies)\n",
    "    * [Executing Tox](#executing_tox)\n",
    "* [Automating the Execution of Your Tests](#automating_the_execution_of_your_tests)\n",
    "* [What’s Next](#what’s_next)\n",
    "    * [Introducing Linters Into Your Application](#introducing_linters_into_your_application)\n",
    "        * [Passive Linting With `flake8`](#passive_linting_with_`flake8`)\n",
    "        * [Aggressive Linting With a Code Formatter](#aggressive_linting_with_a_code_formatter)\n",
    "    * [Keeping Your Test Code Clean](#keeping_your_test_code_clean)\n",
    "    * [Testing for Performance Degradation Between Changes](#testing_for_performance_degradation_between_changes)\n",
    "    * [Testing for Security Flaws in Your Application](#testing_for_security_flaws_in_your_application)\n",
    "* [Conclusion](#conclusion)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da237c1",
   "metadata": {},
   "source": [
    "This tutorial is for anyone who has written a fantastic application in Python but hasn’t yet written any tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27941e3e",
   "metadata": {},
   "source": [
    "Testing in Python is a huge topic and can come with a lot of complexity, but it doesn’t need to be hard. You can get started creating simple tests for your application in a few easy steps and then build on it from there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2970d0c",
   "metadata": {},
   "source": [
    "In this tutorial, you’ll learn how to create a basic test, execute it, and find the bugs before your users do! You’ll learn about the tools available to write and execute tests, check your application’s performance, and even look for security issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb8b4dc",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"testing_your_code\"></a>\n",
    "\n",
    "## Testing Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef383a5",
   "metadata": {},
   "source": [
    "There are many ways to test your code. In this tutorial, you’ll learn the techniques from the most basic steps and work towards advanced methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d66de",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"automated_vs._manual_testing\"></a>\n",
    "\n",
    "### Automated vs. Manual Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca5e2b",
   "metadata": {},
   "source": [
    "The good news is, you’ve probably already created a test without realizing it. Remember when you ran your application and used it for the first time? Did you check the features and experiment using them? That’s known as **exploratory testing** and is a form of manual testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a60191",
   "metadata": {},
   "source": [
    "Exploratory testing is a form of testing that is done without a plan. In an exploratory test, you’re just exploring the application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb524fc0",
   "metadata": {},
   "source": [
    "To have a complete set of manual tests, all you need to do is make a list of all the features your application has, the different types of input it can accept, and the expected results. Now, every time you make a change to your code, you need to go through every single item on that list and check it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb4710d",
   "metadata": {},
   "source": [
    "That doesn’t sound like much fun, does it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da3cabd",
   "metadata": {},
   "source": [
    "This is where automated testing comes in. **Automated testing** is the execution of your test plan (the parts of your application you want to test, the order in which you want to test them, and the expected responses) by a script instead of a human. Python already comes with a set of tools and libraries to help you create automated tests for your application. We’ll explore those tools and libraries in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c325ca",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"unit_tests_vs._integration_tests\"></a>\n",
    "\n",
    "### Unit Tests vs. Integration Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ce52f3",
   "metadata": {},
   "source": [
    "The world of testing has no shortage of terminology, and now that you know the difference between automated and manual testing, it’s time to go a level deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a89ea9c",
   "metadata": {},
   "source": [
    "Think of how you might test the lights on a car. You would turn on the lights (known as the **test step**) and go outside the car or ask a friend to check that the lights are on (known as the **test assertion**). Testing multiple components is known as **integration testing**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1b8433",
   "metadata": {},
   "source": [
    "Think of all the things that need to work correctly in order for a simple task to give the right result. These components are like the parts to your application, all of those classes, functions, and modules you’ve written. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba546d7",
   "metadata": {},
   "source": [
    "A major challenge with integration testing is when an integration test doesn’t give the right result. It’s very hard to diagnose the issue without being able to isolate which part of the system is failing. If the lights didn’t turn on, then maybe the bulbs are broken. Is the battery dead? What about the alternator? Is the car’s computer failing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbde818",
   "metadata": {},
   "source": [
    "If you have a fancy modern car, it will tell you when your light bulbs have gone. It does this using a form of **unit test**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79145f2c",
   "metadata": {},
   "source": [
    "A unit test is a smaller test, one that checks that a single component operates in the right way. A unit test helps you to isolate what is broken in your application and fix it faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b8616e",
   "metadata": {},
   "source": [
    "You have just seen two types of tests:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422fffb0",
   "metadata": {},
   "source": [
    "1. An integration test checks that components in your application operate with each other.\n",
    "2. A unit test checks a small component in your application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bca9899",
   "metadata": {},
   "source": [
    "You can write both integration tests and unit tests in Python. To write a unit test for the built-in function `sum()`, you would check the output of `sum()` against a known output. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b66d3c1",
   "metadata": {},
   "source": [
    "For example, here’s how you check that the `sum()` of the numbers `(1, 2, 3)` equals `6`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba1a3771",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> assert sum([1, 2, 3]) == 6, \"Should be 6\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91062aa9",
   "metadata": {},
   "source": [
    "This will not output anything on the REPL because the values are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2a77d9",
   "metadata": {},
   "source": [
    "If the result from `sum()` is incorrect, this will fail with an `AssertionError` and the message `\"Should be 6\"`. Try an assertion statement again with the wrong values to see an `AssertionError`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3038420b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3402191843.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/b4/tsp68dlx1gz9xlnpgbx21ytc0000gn/T/ipykernel_53029/3402191843.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    Traceback (most recent call last):\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    ">>> assert sum([1, 1, 1]) == 6, \"Should be 6\"\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "AssertionError: Should be 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eff498",
   "metadata": {},
   "source": [
    "In the REPL, you are seeing the raised `AssertionError` because the result of `sum()` does not match `6`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7a0e27",
   "metadata": {},
   "source": [
    "Instead of testing on the REPL, you’ll want to put this into a new Python file called `test_sum.py` and execute it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083fbb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sum():\n",
    "    assert sum([1, 2, 3]) == 6, \"Should be 6\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_sum()\n",
    "    print(\"Everything passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69af0ea",
   "metadata": {},
   "source": [
    "Now you have written a **test case**, an assertion, and an entry point (the command line). You can now execute this at the command line:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc316183",
   "metadata": {},
   "source": [
    "```sh\n",
    "$ python test_sum.py\n",
    "Everything passed\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e03ccf7",
   "metadata": {},
   "source": [
    "You can see the successful result, `Everything passed`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b55feb6",
   "metadata": {},
   "source": [
    "In Python, `sum()` accepts any iterable as its first argument. You tested with a list. Now test with a tuple as well. Create a new file called `test_sum_2.py` with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f64c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sum():\n",
    "    assert sum([1, 2, 3]) == 6, \"Should be 6\"\n",
    "\n",
    "def test_sum_tuple():\n",
    "    assert sum((1, 2, 2)) == 6, \"Should be 6\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_sum()\n",
    "    test_sum_tuple()\n",
    "    print(\"Everything passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416893c8",
   "metadata": {},
   "source": [
    "When you execute `test_sum_2.py`, the script will give an error because the `sum()` of `(1, 2, 2)` is `5`, not `6`. The result of the script gives you the error message, the line of code, and the traceback:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af6e07f",
   "metadata": {},
   "source": [
    "```sh\n",
    "$ python test_sum_2.py\n",
    "Traceback (most recent call last):\n",
    "  File \"test_sum_2.py\", line 9, in <module>\n",
    "    test_sum_tuple()\n",
    "  File \"test_sum_2.py\", line 5, in test_sum_tuple\n",
    "    assert sum((1, 2, 2)) == 6, \"Should be 6\"\n",
    "AssertionError: Should be 6\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27dc392",
   "metadata": {},
   "source": [
    "Here you can see how a mistake in your code gives an error on the console with some information on where the error was and what the expected result was."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d63e7e3",
   "metadata": {},
   "source": [
    "Writing tests in this way is okay for a simple check, but what if more than one fails? This is where test runners come in. The test runner is a special application designed for running tests, checking the output, and giving you tools for debugging and diagnosing tests and applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791fdb58",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"choosing_a_test_runner\"></a>\n",
    "\n",
    "### Choosing a Test Runner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47b7437",
   "metadata": {},
   "source": [
    "There are many test runners available for Python. The one built into the Python standard library is called `unittest`. In this tutorial, you will be using `unittest` test cases and the `unittest` test runner. The principles of `unittest` are easily portable to other frameworks. The three most popular test runners are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31538c7d",
   "metadata": {},
   "source": [
    "- `unittest`\n",
    "- `nose` or `nose2`\n",
    "- `pytest`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2543a18",
   "metadata": {},
   "source": [
    "Choosing the best test runner for your requirements and level of experience is important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb693ad9",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"`unittest`\"></a>\n",
    "\n",
    "#### `unittest`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba523106",
   "metadata": {},
   "source": [
    "`unittest` has been built into the Python standard library since version 2.1. You’ll probably see it in commercial Python applications and open-source projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047b85a2",
   "metadata": {},
   "source": [
    "`unittest` contains both a testing framework and a test runner. `unittest` has some important requirements for writing and executing tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc73e730",
   "metadata": {},
   "source": [
    "`unittest` requires that:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe507bf3",
   "metadata": {},
   "source": [
    "- You put your tests into classes as methods\n",
    "- You use a series of special assertion methods in the `unittest.TestCase` class instead of the built-in `assert` statement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ffb3bd",
   "metadata": {},
   "source": [
    "To convert the earlier example to a `unittest` test case, you would have to:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc6e513",
   "metadata": {},
   "source": [
    "1. [Import](https://realpython.com/absolute-vs-relative-python-imports/) `unittest` from the standard library\n",
    "2. Create a class called `TestSum` that inherits from the `TestCase` class\n",
    "3. Convert the test functions into methods by adding `self` as the first argument\n",
    "4. Change the assertions to use the `self.assertEqual()` method on the `TestCase` class\n",
    "5. Change the command-line entry point to call `unittest.main()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522b7f51",
   "metadata": {},
   "source": [
    "Follow those steps by creating a new file `test_sum_unittest.py` with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d97e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251d94b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestSum(unittest.TestCase):\n",
    "\n",
    "    def test_sum(self):\n",
    "        self.assertEqual(sum([1, 2, 3]), 6, \"Should be 6\")\n",
    "\n",
    "    def test_sum_tuple(self):\n",
    "        self.assertEqual(sum((1, 2, 2)), 6, \"Should be 6\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9a8f54",
   "metadata": {},
   "source": [
    "If you execute this at the command line, you’ll see one success (indicated with `.`) and one failure (indicated with `F`):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5593c1",
   "metadata": {},
   "source": [
    "```sh\n",
    "$ python test_sum_unittest.py\n",
    ".F\n",
    "======================================================================\n",
    "FAIL: test_sum_tuple (__main__.TestSum)\n",
    "----------------------------------------------------------------------\n",
    "Traceback (most recent call last):\n",
    "  File \"test_sum_unittest.py\", line 9, in test_sum_tuple\n",
    "    self.assertEqual(sum((1, 2, 2)), 6, \"Should be 6\")\n",
    "AssertionError: Should be 6\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "Ran 2 tests in 0.001s\n",
    "\n",
    "FAILED (failures=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7cca7c",
   "metadata": {},
   "source": [
    "You have just executed two tests using the `unittest` test runner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6367ce3b",
   "metadata": {},
   "source": [
    "For more information on `unittest`, you can explore the [unittest Documentation](https://docs.python.org/3/library/unittest.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7197fcaa",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"`nose`\"></a>\n",
    "\n",
    "#### `nose`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a99028",
   "metadata": {},
   "source": [
    "You may find that over time, as you write hundreds or even thousands of tests for your application, it becomes increasingly hard to understand and use the output from `unittest`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fae09e9",
   "metadata": {},
   "source": [
    "`nose` is compatible with any tests written using the `unittest` framework and can be used as a drop-in replacement for the `unittest` test runner. The development of `nose` as an open-source application fell behind, and a fork called `nose2` was created. If you’re starting from scratch, it is recommended that you use `nose2` instead of `nose`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e7dc42",
   "metadata": {},
   "source": [
    "To get started with `nose2`, install `nose2` from PyPI and execute it on the command line. `nose2` will try to discover all test scripts named `test*.py` and test cases inheriting from `unittest.TestCase` in your current directory:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35a7aff",
   "metadata": {},
   "source": [
    "```sh\n",
    "$ pip install nose2\n",
    "$ python -m nose2\n",
    ".F\n",
    "======================================================================\n",
    "FAIL: test_sum_tuple (__main__.TestSum)\n",
    "----------------------------------------------------------------------\n",
    "Traceback (most recent call last):\n",
    "  File \"test_sum_unittest.py\", line 9, in test_sum_tuple\n",
    "    self.assertEqual(sum((1, 2, 2)), 6, \"Should be 6\")\n",
    "AssertionError: Should be 6\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "Ran 2 tests in 0.001s\n",
    "\n",
    "FAILED (failures=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7985671c",
   "metadata": {},
   "source": [
    "You have just executed the test you created in `test_sum_unittest.py` from the `nose2` test runner. `nose2` offers many command-line flags for filtering the tests that you execute. For more information, you can explore the [Nose 2 documentation](https://nose2.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4093b",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"`pytest`\"></a>\n",
    "\n",
    "#### `pytest`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ab251d",
   "metadata": {},
   "source": [
    "[`pytest`](https://realpython.com/pytest-python-testing/) supports execution of `unittest` test cases. The real advantage of `pytest` comes by writing `pytest` test cases. `pytest` test cases are a series of functions in a Python file starting with the name `test_`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af57baf2",
   "metadata": {},
   "source": [
    "`pytest` has some other great features:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e8016",
   "metadata": {},
   "source": [
    "- Support for the built-in `assert` statement instead of using special `self.assert*()` methods\n",
    "- Support for filtering for test cases\n",
    "- Ability to rerun from the last failing test\n",
    "- An ecosystem of hundreds of plugins to extend the functionality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0f0a10",
   "metadata": {},
   "source": [
    "Writing the `TestSum` test case example for `pytest` would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517de7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sum():\n",
    "    assert sum([1, 2, 3]) == 6, \"Should be 6\"\n",
    "\n",
    "def test_sum_tuple():\n",
    "    assert sum((1, 2, 2)) == 6, \"Should be 6\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353b5dee",
   "metadata": {},
   "source": [
    "You have dropped the `TestCase`, any use of classes, and the command-line entry point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc996d7",
   "metadata": {},
   "source": [
    "More information can be found at the [Pytest Documentation Website](https://docs.pytest.org/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804a53d8",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"writing_your_first_test\"></a>\n",
    "\n",
    "## Writing Your First Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09987524",
   "metadata": {},
   "source": [
    "Let’s bring together what you’ve learned so far and, instead of testing the built-in `sum()` function, test a simple implementation of the same requirement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf3677a",
   "metadata": {},
   "source": [
    "Create a new project folder and, inside that, create a new folder called `my_sum`. Inside `my_sum`, create an empty file called `__init__.py`. Creating the `__init__.py` file means that the `my_sum` folder can be imported as a module from the parent directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f527ce1e",
   "metadata": {},
   "source": [
    "Your project folder should look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fe750c",
   "metadata": {},
   "source": [
    "```\n",
    "project/\n",
    "│\n",
    "└── my_sum/\n",
    "    └── __init__.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc129034",
   "metadata": {},
   "source": [
    "Open up `my_sum/__init__.py` and create a new function called `sum()`, which takes an iterable (a list, tuple, or set) and adds the values together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad8f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum(arg):\n",
    "    total = 0\n",
    "    for val in arg:\n",
    "        total += val\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7e0a1c",
   "metadata": {},
   "source": [
    "This code example creates a variable called `total`, iterates over all the values in `arg`, and adds them to `total`. It then returns the result once the iterable has been exhausted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e817e8",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"where_to_write_the_test\"></a>\n",
    "\n",
    "### Where to Write the Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92539e7a",
   "metadata": {},
   "source": [
    "To get started writing tests, you can simply create a file called `test.py`, which will contain your first test case. Because the file will need to be able to import your application to be able to test it, you want to place `test.py` above the package folder, so your directory tree will look something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83ca7ee",
   "metadata": {},
   "source": [
    "```\n",
    "project/\n",
    "│\n",
    "├── my_sum/\n",
    "│   └── __init__.py\n",
    "|\n",
    "└── test.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d31279f",
   "metadata": {},
   "source": [
    "You’ll find that, as you add more and more tests, your single file will become cluttered and hard to maintain, so you can create a folder called `tests/` and split the tests into multiple files. It is convention to ensure each file starts with `test_` so all test runners will assume that Python file contains tests to be executed. Some very large projects split tests into more subdirectories based on their purpose or usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d43957a",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"how_to_structure_a_simple_test\"></a>\n",
    "\n",
    "### How to Structure a Simple Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1efb22b",
   "metadata": {},
   "source": [
    "Before you dive into writing tests, you’ll want to first make a couple of decisions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462e531f",
   "metadata": {},
   "source": [
    "1. What do you want to test?\n",
    "2. Are you writing a unit test or an integration test?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dedb57",
   "metadata": {},
   "source": [
    "Then the structure of a test should loosely follow this workflow:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232ee4e6",
   "metadata": {},
   "source": [
    "1. Create your inputs\n",
    "2. Execute the code being tested, capturing the output\n",
    "3. Compare the output with an expected result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a820b7",
   "metadata": {},
   "source": [
    "For this application, you’re testing `sum()`. There are many behaviors in `sum()` you could check, such as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03afd2ef",
   "metadata": {},
   "source": [
    "- Can it sum a list of whole numbers (integers)?\n",
    "- Can it sum a tuple or set?\n",
    "- Can it sum a list of floats?\n",
    "- What happens when you provide it with a bad value, such as a single integer or a string?\n",
    "- What happens when one of the values is negative?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929f9f34",
   "metadata": {},
   "source": [
    "The most simple test would be a list of integers. Create a file, `test.py` with the following Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e501f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_sum import sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "603c05e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sum_list_int(self):\n",
    "    \"\"\"\n",
    "    Test that it can sum a list of integers\n",
    "    \"\"\"\n",
    "    data = [1, 2, 3]\n",
    "    result = sum(data)\n",
    "    assert result == 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3811c2b3-8460-4ee0-8070-df5ba69ba240",
   "metadata": {},
   "source": [
    "To run the test case, you should run `pytest <path_to_test_file_or_directory>`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800ed5a1",
   "metadata": {},
   "source": [
    "This code example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5449fbda",
   "metadata": {},
   "source": [
    "1. Imports `sum()` from the `my_sum` package you created\n",
    "2. Defines a new test case class called `test_sum_list_int`.\n",
    "3. Defines a test method, `.test_sum_list_int()`, to test a list of integers. The method `.test_sum_list_int()` will:\n",
    "\n",
    "* Declare a variable `data` with a list of numbers `(1, 2, 3)`\n",
    "* Assign the result of `my_sum.sum(data)` to a `result` variable\n",
    "* Assert that the value of `result` equals `6` by using the `assert`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3863a2d1",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"side_effects\"></a>\n",
    "\n",
    "### Side Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555fa1cd",
   "metadata": {},
   "source": [
    "When you’re writing tests, it’s often not as simple as looking at the return value of a function. Often, executing a piece of code will alter other things in the environment, such as the attribute of a class, a file on the filesystem, or a value in a database. These are known as **side effects** and are an important part of testing. Decide if the side effect is being tested before including it in your list of assertions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1b8e3",
   "metadata": {},
   "source": [
    "If you find that the unit of code you want to test has lots of side effects, you might be breaking the [Single Responsibility Principle](https://en.wikipedia.org/wiki/Single_responsibility_principle). Breaking the Single Responsibility Principle means the piece of code is doing too many things and would be better off being refactored. Following the Single Responsibility Principle is a great way to design code that it is easy to write repeatable and simple unit tests for, and ultimately, reliable applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885b8a06",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"more_advanced_testing_scenarios\"></a>\n",
    "\n",
    "## More Advanced Testing Scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f675195b",
   "metadata": {},
   "source": [
    "Before you step into creating tests for your application, remember the three basic steps of every test:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5064bfd",
   "metadata": {},
   "source": [
    "1. Create your inputs\n",
    "2. Execute the code, capturing the output\n",
    "3. Compare the output with an expected result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12ded25",
   "metadata": {},
   "source": [
    "It’s not always as easy as creating a static value for the input like a string or a number. Sometimes, your application will require an instance of a class or a context. What do you do then?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c981b3",
   "metadata": {},
   "source": [
    "The data that you create as an input is known as a **fixture**. It’s common practice to create fixtures and reuse them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ef2e51",
   "metadata": {},
   "source": [
    "If you’re running the same test and passing different values each time and expecting the same result, this is known as **parameterization**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdf14e0",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"isolating_behaviors_in_your_application\"></a>\n",
    "\n",
    "### Isolating Behaviors in Your Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8979cff",
   "metadata": {},
   "source": [
    "Earlier in the tutorial, you learned what a side effect is. Side effects make unit testing harder since, each time a test is run, it might give a different result, or even worse, one test could impact the state of the application and cause another test to fail! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77150378",
   "metadata": {},
   "source": [
    "<img src=\"images/getting-started-with-testing-in-python/YXhT6fA.d277d5317026.gif\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61bd2c8",
   "metadata": {},
   "source": [
    "There are some simple techniques you can use to test parts of your application that have many side effects:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefab1b9",
   "metadata": {},
   "source": [
    "- Refactoring code to follow the Single Responsibility Principle\n",
    "- Mocking out any method or function calls to remove side effects\n",
    "- Using integration testing instead of unit testing for this piece of the application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be167c84",
   "metadata": {},
   "source": [
    "Mocking will be explained in details in the next section, **Effective Python Testing with `pytest`**. t allows you to replace parts of your system under test with mock objects and make assertions about how they have been used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89262c0",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"writing_integration_tests\"></a>\n",
    "\n",
    "### Writing Integration Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd74ab2",
   "metadata": {},
   "source": [
    "So far, you’ve been learning mainly about unit testing. Unit testing is a great way to build predictable and stable code. But at the end of the day, your application needs to work when it starts!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea602eb",
   "metadata": {},
   "source": [
    "Integration testing is the testing of multiple components of the application to check that they work together. Integration testing might require acting like a consumer or user of the application by:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84131227",
   "metadata": {},
   "source": [
    "- Calling an HTTP REST API\n",
    "- Calling a Python API\n",
    "- Calling a web service\n",
    "- Running a command line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc095e02",
   "metadata": {},
   "source": [
    "Each of these types of integration tests can be written in the same way as a unit test, following the Input, Execute, and Assert pattern. The most significant difference is that integration tests are checking more components at once and therefore will have more side effects than a unit test. Also, integration tests will require more fixtures to be in place, like a database, a network socket, or a configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390e793a",
   "metadata": {},
   "source": [
    "This is why it’s good practice to separate your unit tests and your integration tests. The creation of fixtures required for an integration like a test database and the test cases themselves often take a lot longer to execute than unit tests, so you may only want to run integration tests before you push to production instead of once on every commit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cbab16",
   "metadata": {},
   "source": [
    "A simple way to separate unit and integration tests is simply to put them in different folders:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725a7f82",
   "metadata": {},
   "source": [
    "```\n",
    "project/\n",
    "│\n",
    "├── my_app/\n",
    "│   └── __init__.py\n",
    "│\n",
    "└── tests/\n",
    "    |\n",
    "    ├── unit/\n",
    "    |   ├── __init__.py\n",
    "    |   └── test_sum.py\n",
    "    |\n",
    "    └── integration/\n",
    "        ├── __init__.py\n",
    "        └── test_integration.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173f7bbf",
   "metadata": {},
   "source": [
    "There are many ways to execute only a select group of tests. The specify source directory flag, `-s`, can be added to `unittest discover` with the path containing the tests:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762d6952",
   "metadata": {},
   "source": [
    "```sh\n",
    "$ python -m unittest discover -s tests/integration\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46407299",
   "metadata": {},
   "source": [
    "`unittest` will have given you the results of all the tests within the `tests/integration` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52686f70",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"testing_in_multiple_environments\"></a>\n",
    "\n",
    "## Testing in Multiple Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d347a",
   "metadata": {},
   "source": [
    "So far, you’ve been testing against a single version of Python using a virtual environment with a specific set of dependencies. You might want to check that your application works on multiple versions of Python, or multiple versions of a package. Tox is an application that automates testing in multiple environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddffc380",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"installing_tox\"></a>\n",
    "\n",
    "### Installing Tox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7558dc0",
   "metadata": {},
   "source": [
    "Tox is available on PyPI as a package to install via [`pip`](https://realpython.com/what-is-pip/):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a9c5b0",
   "metadata": {},
   "source": [
    "```sh\n",
    "$ pip install tox\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff5c54",
   "metadata": {},
   "source": [
    "Now that you have Tox installed, it needs to be configured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dd492e",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"configuring_tox_for_your_dependencies\"></a>\n",
    "\n",
    "### Configuring Tox for Your Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f0ab49",
   "metadata": {},
   "source": [
    "Tox is configured via a configuration file in your project directory. The Tox configuration file contains the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9180f215",
   "metadata": {},
   "source": [
    "- The command to run in order to execute tests\n",
    "- Any additional packages required before executing\n",
    "- The target Python versions to test against\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f51c83",
   "metadata": {},
   "source": [
    "Instead of having to learn the Tox configuration syntax, you can get a head start by running the quickstart application:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668eaff3",
   "metadata": {},
   "source": [
    "```sh\n",
    "$ tox-quickstart\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8af7c3",
   "metadata": {},
   "source": [
    "The Tox configuration tool will ask you those questions and create a file similar to the following in `tox.ini`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb09b16",
   "metadata": {},
   "source": [
    "```ini\n",
    "[tox]\n",
    "envlist = py27, py36\n",
    "\n",
    "[testenv]\n",
    "deps =\n",
    "\n",
    "commands =\n",
    "    python -m unittest discover\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9fd626",
   "metadata": {},
   "source": [
    "Before you can run Tox, it requires that you have a `setup.py` file in your application folder containing the steps to install your package. If you don’t have one, you can follow [this guide](https://packaging.python.org/tutorials/packaging-projects/#setup-py) on how to create a `setup.py` before you continue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bda5f31",
   "metadata": {},
   "source": [
    "Alternatively, if your project is not for distribution on PyPI, you can skip this requirement by adding the following line in the `tox.ini` file under the `[tox]` heading:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5411e4a3",
   "metadata": {},
   "source": [
    "```ini\n",
    "[tox]\n",
    "envlist = py27, py36\n",
    "skipsdist=True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccaf719",
   "metadata": {},
   "source": [
    "If you don’t create a `setup.py`, and your application has some dependencies from PyPI, you’ll need to specify those on a number of lines under the `[testenv]` section. For example, Django would require the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8cfa70",
   "metadata": {},
   "source": [
    "```ini\n",
    "[testenv]\n",
    "deps = django\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf71e0f",
   "metadata": {},
   "source": [
    "Once you have completed that stage, you’re ready to run the tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a791a",
   "metadata": {},
   "source": [
    "You can now execute Tox, and it will create two virtual environments: one for Python 2.7 and one for Python 3.6. The Tox directory is called `.tox/`. Within the `.tox/` directory, Tox will execute `python -m unittest discover` against each virtual environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d972a9",
   "metadata": {},
   "source": [
    "You can run this process by calling Tox at the command line:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cd212b",
   "metadata": {},
   "source": [
    "```sh\n",
    "$ tox\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025cc977",
   "metadata": {},
   "source": [
    "Tox will output the results of your tests against each environment. The first time it runs, Tox takes a little bit of time to create the virtual environments, but once it has, the second execution will be a lot faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c2598",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"executing_tox\"></a>\n",
    "\n",
    "### Executing Tox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf79f0d",
   "metadata": {},
   "source": [
    "The output of Tox is quite straightforward. It creates an environment for each version, installs your dependencies, and then runs the test commands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af70d2f0",
   "metadata": {},
   "source": [
    "There are some additional command line options that are great to remember."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680a147",
   "metadata": {},
   "source": [
    "Run only a single environment, such as Python 3.6:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc1b1e6",
   "metadata": {},
   "source": [
    "```sh\n",
    "$ tox -e py36\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837b29a3",
   "metadata": {},
   "source": [
    "Recreate the virtual environments, in case your dependencies have changed or [site-packages](https://docs.python.org/3/install/#how-installation-works) is corrupt:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b48cc6",
   "metadata": {},
   "source": [
    "```sh\n",
    "$ tox -r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f43165",
   "metadata": {},
   "source": [
    "Run Tox with less verbose output:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26dbf55",
   "metadata": {},
   "source": [
    "```sh\n",
    "$ tox -q\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284cca99",
   "metadata": {},
   "source": [
    "Running Tox with more verbose output:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f97c1c9",
   "metadata": {},
   "source": [
    "```sh\n",
    "$ tox -v\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaeabc8",
   "metadata": {},
   "source": [
    "More information on Tox can be found at the [Tox Documentation Website](https://tox.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60015697",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"what’s_next\"></a>\n",
    "\n",
    "## What’s Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c08238",
   "metadata": {},
   "source": [
    "Now that you’ve learned how to create tests, execute them, include them in your project, and even execute them automatically, there are a few advanced techniques you might find handy as your test library grows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec66823",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"keeping_your_test_code_clean\"></a>\n",
    "\n",
    "### Keeping Your Test Code Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49526158",
   "metadata": {},
   "source": [
    "When writing tests, you may find that you end up copying and pasting code a lot more than you would in regular applications. Tests can be very repetitive at times, but that is by no means a reason to leave your code sloppy and hard to maintain. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b5ae16",
   "metadata": {},
   "source": [
    "Over time, you will develop a lot of [technical debt](https://martinfowler.com/bliki/TechnicalDebt.html) in your test code, and if you have significant changes to your application that require changes to your tests, it can be a more cumbersome task than necessary because of the way you structured them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0567270b",
   "metadata": {},
   "source": [
    "Try to follow the **DRY** principle when writing tests: **D**on’t **R**epeat **Y**ourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19017cb4",
   "metadata": {},
   "source": [
    "Test fixtures and functions are a great way to produce test code that is easier to maintain. Also, readability counts. Consider deploying a linting tool like `flake8` over your test code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f40b513",
   "metadata": {},
   "source": [
    "```sh\n",
    "$ flake8 --max-line-length=120 tests/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f86619",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"testing_for_performance_degradation_between_changes\"></a>\n",
    "\n",
    "### Testing for Performance Degradation Between Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1fdfb5",
   "metadata": {},
   "source": [
    "There are many ways to benchmark code in Python. The standard library provides the `timeit` module, which can time functions a number of times and give you the distribution. This example will execute `test()` 100 times and `print()` the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02252afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # ... your code\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import timeit\n",
    "    print(timeit.timeit(\"test()\", setup=\"from __main__ import test\", number=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9772f29",
   "metadata": {},
   "source": [
    "Another option, if you decided to use `pytest` as a test runner, is the `pytest-benchmark` plugin. This provides a `pytest` fixture called `benchmark`. You can pass `benchmark()` any callable, and it will log the timing of the callable to the results of `pytest`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14615561",
   "metadata": {},
   "source": [
    "You can install `pytest-benchmark` from PyPI using `pip`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1823e9",
   "metadata": {},
   "source": [
    "```sh\n",
    "$ pip install pytest-benchmark\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d162eff",
   "metadata": {},
   "source": [
    "Then, you can add a test that uses the fixture and passes the callable to be executed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c492c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_my_function(benchmark):\n",
    "    result = benchmark(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d65be74",
   "metadata": {},
   "source": [
    "Execution of `pytest` will now give you benchmark results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4158dc59",
   "metadata": {},
   "source": [
    "<img src=\"images/getting-started-with-testing-in-python/pytest-bench-screen.6d83bffe8e21.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5542e58",
   "metadata": {},
   "source": [
    "More information is available at the [Documentation Website](https://pytest-benchmark.readthedocs.io/en/latest/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23ed2411",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"conclusion\"></a>\n",
    "\n",
    "## <img src=\"../../images/logos/checkmark.png\" width=\"20\"/> Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd7ba03",
   "metadata": {},
   "source": [
    "Python has made testing accessible by building in the commands and libraries you need to validate that your applications work as designed. Getting started with testing in Python needn’t be complicated: you can use `pytest` and write small, maintainable methods to validate your code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84df22d",
   "metadata": {},
   "source": [
    "Thank you for reading. I hope you have a bug-free future with Python!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
